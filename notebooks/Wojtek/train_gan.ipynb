{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_gan",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK9yoJaiBLUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "#from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "#from tensorflow.keras.initializers import glorot_uniform\n",
        "#from tensorflow.keras.initializers import RandomUniform\n",
        " \n",
        "# define the standalone discriminator model\n",
        "def define_discriminator(in_shape):\n",
        "    model = Sequential()\n",
        "    # normal\n",
        "    model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample\n",
        "    model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))   \n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # classifier\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = Adam(lr=0.0004, beta_1=0.5)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model\n",
        " \n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim, output_shape):\n",
        "    start_height = output_shape[0] // 8\n",
        "    start_width = output_shape[1] // 8\n",
        "    final_channels = output_shape[2]\n",
        "    \n",
        "    model = Sequential()\n",
        "    # foundation for 4x4 image\n",
        "    n_nodes = 256 * start_width * start_height\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((start_height, start_width , 256)))\n",
        "    # upsample to 2*start_width x 2*start_height\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 4*start_width x 4*start_height\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 8*start_width x 8*start_height\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # output layer\n",
        "    model.add(Conv2D(final_channels, (3,3), activation='tanh', padding='same'))\n",
        "    return model\n",
        "\n",
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model, loss='binary_crossentropy', optimizer=None):\n",
        "    # make weights in the discriminator not trainable\n",
        "    d_model.trainable = False\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(g_model)\n",
        "    # add the discriminator\n",
        "    model.add(d_model)\n",
        "    # compile model\n",
        "    if not optimizer:\n",
        "        optimizer = Adam(lr=0.0004, beta_1=0.5)\n",
        "    model.compile(loss=loss, optimizer=optimizer)\n",
        "    return model\n",
        " "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33J-AuCJBP-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples, multiplier=1.0):\n",
        "    # choose random instances\n",
        "    ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "    # select images\n",
        "    X = dataset[ix]\n",
        "    # generate class labels, -1 for 'real'\n",
        "    y = np.ones((n_samples, 1)) * multiplier\n",
        "    return X, y\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples, multiplier=1.0):\n",
        "    # generate points in latent space\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    # predict outputs\n",
        "    X = generator.predict(x_input)\n",
        "    # create class labels with 1.0 for 'fake'\n",
        "    y = np.ones((n_samples, 1)) * multiplier\n",
        "    return X, y\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = np.random.randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(genenerator, discriminator, gan_model, dataset, latent_dim, output_path,\n",
        "          real_samples_multiplier=1.0, fake_samples_multiplier=0.0, discriminator_batches=1,\n",
        "          n_epochs=200, n_batch=128):\n",
        "    batch_per_epoch = dataset.shape[0] // n_batch\n",
        "    half_batch = n_batch // 2\n",
        "    seed = generate_latent_points(latent_dim, 54)\n",
        "    n_steps = batch_per_epoch * n_epochs\n",
        "\t\n",
        "    history = {'discriminator_real_loss': [],\n",
        "               'discriminator_fake_loss': [],\n",
        "               'generator_loss': []}\n",
        "    for step in range(n_steps):\n",
        "        epoch = step // batch_per_epoch\n",
        "        disc_loss_real = 0.0\n",
        "        disc_loss_fake = 0.0\n",
        "        for disc_batch in range(discriminator_batches):\n",
        "            X_real, y_real = generate_real_samples(dataset, half_batch,\n",
        "                                                   multiplier=real_samples_multiplier)\n",
        "            disc_loss_real += discriminator.train_on_batch(X_real, y_real)\n",
        "            X_fake, y_fake = generate_fake_samples(genenerator, latent_dim, half_batch,\n",
        "                                                   multiplier=fake_samples_multiplier)\n",
        "            disc_loss_fake += discriminator.train_on_batch(X_fake, y_fake)\n",
        "        disc_loss_real /= discriminator_batches\n",
        "        disc_loss_fake /= discriminator_batches\n",
        "        \n",
        "        X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "        y_gan = np.ones((n_batch, 1)) * real_samples_multiplier\n",
        "        g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "        \n",
        "        history['discriminator_real_loss'].append(disc_loss_real)\n",
        "        history['discriminator_fake_loss'].append(disc_loss_fake)\n",
        "        history['generator_loss'].append(g_loss)\n",
        "            \n",
        "        if not (step) % batch_per_epoch:\n",
        "            epoch = step // batch_per_epoch+1\n",
        "            print('epoch: %d, discriminator_real_loss=%.3f, discriminator_fake_loss=%.3f, generator_loss=%.3f' % (epoch, disc_loss_real, disc_loss_fake, g_loss))\n",
        "            if not epoch % 10:\n",
        "                # save images:\n",
        "                save_images(epoch, 9, 6, seed, output_path + '/images', genenerator,\n",
        "                            image_size=(X_fake.shape[1], X_fake.shape[2], X_fake.shape[3]))\n",
        "                # save the generator model tile file\n",
        "                save_generator_path = f'{output_path}/generator_models'\n",
        "                save_discriminator_path = f'{output_path}/discriminator_models'\n",
        "                if not os.path.exists(save_generator_path):\n",
        "                    os.makedirs(save_generator_path)\n",
        "                if not os.path.exists(save_discriminator_path):\n",
        "                    os.makedirs(save_discriminator_path)\n",
        "                genenerator.save(save_generator_path + f'/generator_model_{epoch}.h5')\n",
        "                discriminator.save(save_discriminator_path + f'/discriminator_model_{epoch}.h5')\n",
        "    return history\n",
        "            \n",
        "def save_images(epoch, n_cols, n_rows, seed, output_path, model, preview_margin=16, image_size=(32, 32)): \n",
        "    height = image_size[0]\n",
        "    width = image_size[1]\n",
        "    image_array = np.full((preview_margin + (n_rows * (height+preview_margin)), \n",
        "                           preview_margin + (n_cols * (width+preview_margin)), image_size[2]), \n",
        "                          255, dtype=np.uint8)\n",
        "                \n",
        "    generated_images = model.predict(seed)\n",
        "    generated_images = (generated_images + 1.0) * 127.5\n",
        "    generated_images = np.round(generated_images).astype(np.uint8)\n",
        "    if image_size[2] == 4:\n",
        "        generated_images[(generated_images[:, :, :, 3] == 127) | (generated_images[:, :, :, 3] == 128)] = 0\n",
        "\n",
        "\n",
        "    image_count = 0\n",
        "    for row in range(n_rows):\n",
        "        for col in range(n_cols):\n",
        "            r = row * (height+preview_margin) + preview_margin\n",
        "            c = col * (width+preview_margin) + preview_margin\n",
        "            image_array[r:r+height,c:c+width] = generated_images[image_count]\n",
        "            image_count += 1\n",
        "    \n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "    \n",
        "    filename = os.path.join(output_path,f\"train-{epoch}.png\")\n",
        "    im = Image.fromarray(image_array)\n",
        "    im.save(filename)\n",
        "    "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKLNxnPNCWVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d37eb42-f2e9-4bd4-cdd3-b179cd46511d"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "drive = './drive/My Drive/margonem_assets_generation/'\n",
        "output_path = drive + 'results/gan/gan_no_soft_v5'\n",
        "dataset = np.load(drive + 'dataset.npy')\n",
        "background_percentage = (dataset[:, :, :, 3] == 0.0).sum(axis=(1, 2))\n",
        "#quantiles = np.quantile(background_percentage, (0.1, 0.95))\n",
        "#mask = (background_percentage >= quantiles[0]) & (background_percentage <= quantiles[1])\n",
        "#dataset = dataset[mask]\n",
        "dataset = dataset[:, :, :, :-1]\n",
        "print(dataset.shape)\n",
        "with open(drive + 'models/gan_config.json') as handle:\n",
        "    params = json.loads(handle.read())\n",
        "shape = (dataset.shape[1], dataset.shape[2], dataset.shape[3])\n",
        "latent_dim = 100"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3835, 48, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2cXtt91DTHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "12fc89b4-1d6d-46ec-d847-be0523859a3f"
      },
      "source": [
        "img = dataset[0]\n",
        "img = (img + 1.0) * 127.5\n",
        "img = np.round(img)\n",
        "img = np.clip(img, 0, 255)\n",
        "img = img.astype(np.uint8)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(img)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb800e80ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3Nm59c6D5Z-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3d07f771-b6c6-401e-e806-45a052602922"
      },
      "source": [
        "params"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'discriminator_batches': 1,\n",
              " 'fake_samples_multiplier': 0.9,\n",
              " 'n_batch': 128,\n",
              " 'n_epochs': 2000,\n",
              " 'real_samples_multiplier': 0.1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co2MAq3tBSvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2fd3b33-72f3-42bd-b934-3adebcefa43c"
      },
      "source": [
        "d_model = define_discriminator(shape)\n",
        "g_model = define_generator(latent_dim, shape)\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "history = train(g_model, d_model, gan_model, dataset, latent_dim, output_path, **params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1, discriminator_real_loss=0.152, discriminator_fake_loss=0.163, generator_loss=0.158\n",
            "epoch: 2, discriminator_real_loss=0.010, discriminator_fake_loss=0.010, generator_loss=0.810\n",
            "epoch: 3, discriminator_real_loss=0.019, discriminator_fake_loss=0.023, generator_loss=0.722\n",
            "epoch: 4, discriminator_real_loss=0.051, discriminator_fake_loss=0.071, generator_loss=0.686\n",
            "epoch: 5, discriminator_real_loss=0.021, discriminator_fake_loss=0.086, generator_loss=0.633\n",
            "epoch: 6, discriminator_real_loss=0.018, discriminator_fake_loss=0.056, generator_loss=0.706\n",
            "epoch: 7, discriminator_real_loss=0.043, discriminator_fake_loss=0.011, generator_loss=0.659\n",
            "epoch: 8, discriminator_real_loss=0.052, discriminator_fake_loss=0.009, generator_loss=0.788\n",
            "epoch: 9, discriminator_real_loss=0.045, discriminator_fake_loss=0.015, generator_loss=0.714\n",
            "epoch: 10, discriminator_real_loss=0.046, discriminator_fake_loss=0.031, generator_loss=0.705\n",
            "epoch: 11, discriminator_real_loss=0.047, discriminator_fake_loss=0.003, generator_loss=0.621\n",
            "epoch: 12, discriminator_real_loss=0.006, discriminator_fake_loss=0.019, generator_loss=0.703\n",
            "epoch: 13, discriminator_real_loss=0.014, discriminator_fake_loss=0.003, generator_loss=0.715\n",
            "epoch: 14, discriminator_real_loss=0.017, discriminator_fake_loss=0.005, generator_loss=0.646\n",
            "epoch: 15, discriminator_real_loss=0.008, discriminator_fake_loss=0.048, generator_loss=0.687\n",
            "epoch: 16, discriminator_real_loss=0.039, discriminator_fake_loss=0.003, generator_loss=0.641\n",
            "epoch: 17, discriminator_real_loss=0.061, discriminator_fake_loss=0.003, generator_loss=0.690\n",
            "epoch: 18, discriminator_real_loss=0.032, discriminator_fake_loss=0.024, generator_loss=0.658\n",
            "epoch: 19, discriminator_real_loss=0.017, discriminator_fake_loss=0.019, generator_loss=0.711\n",
            "epoch: 20, discriminator_real_loss=0.035, discriminator_fake_loss=0.017, generator_loss=0.676\n",
            "epoch: 21, discriminator_real_loss=0.044, discriminator_fake_loss=0.020, generator_loss=0.682\n",
            "epoch: 22, discriminator_real_loss=0.065, discriminator_fake_loss=0.006, generator_loss=0.663\n",
            "epoch: 23, discriminator_real_loss=0.017, discriminator_fake_loss=0.007, generator_loss=0.644\n",
            "epoch: 24, discriminator_real_loss=0.031, discriminator_fake_loss=0.004, generator_loss=0.753\n",
            "epoch: 25, discriminator_real_loss=0.032, discriminator_fake_loss=0.014, generator_loss=0.703\n",
            "epoch: 26, discriminator_real_loss=0.014, discriminator_fake_loss=0.004, generator_loss=0.677\n",
            "epoch: 27, discriminator_real_loss=0.009, discriminator_fake_loss=0.058, generator_loss=0.772\n",
            "epoch: 28, discriminator_real_loss=0.026, discriminator_fake_loss=0.025, generator_loss=0.684\n",
            "epoch: 29, discriminator_real_loss=0.027, discriminator_fake_loss=0.014, generator_loss=0.691\n",
            "epoch: 30, discriminator_real_loss=0.010, discriminator_fake_loss=0.017, generator_loss=0.684\n",
            "epoch: 31, discriminator_real_loss=0.024, discriminator_fake_loss=0.051, generator_loss=0.690\n",
            "epoch: 32, discriminator_real_loss=0.045, discriminator_fake_loss=0.049, generator_loss=0.719\n",
            "epoch: 33, discriminator_real_loss=0.025, discriminator_fake_loss=0.004, generator_loss=0.652\n",
            "epoch: 34, discriminator_real_loss=0.011, discriminator_fake_loss=0.013, generator_loss=0.680\n",
            "epoch: 35, discriminator_real_loss=0.048, discriminator_fake_loss=0.028, generator_loss=0.678\n",
            "epoch: 36, discriminator_real_loss=0.050, discriminator_fake_loss=0.033, generator_loss=0.731\n",
            "epoch: 37, discriminator_real_loss=0.023, discriminator_fake_loss=0.018, generator_loss=0.679\n",
            "epoch: 38, discriminator_real_loss=0.024, discriminator_fake_loss=0.021, generator_loss=0.711\n",
            "epoch: 39, discriminator_real_loss=0.113, discriminator_fake_loss=0.007, generator_loss=0.716\n",
            "epoch: 40, discriminator_real_loss=0.062, discriminator_fake_loss=0.010, generator_loss=0.637\n",
            "epoch: 41, discriminator_real_loss=0.016, discriminator_fake_loss=0.040, generator_loss=0.754\n",
            "epoch: 42, discriminator_real_loss=0.021, discriminator_fake_loss=0.005, generator_loss=0.656\n",
            "epoch: 43, discriminator_real_loss=0.050, discriminator_fake_loss=0.013, generator_loss=0.648\n",
            "epoch: 44, discriminator_real_loss=0.027, discriminator_fake_loss=0.029, generator_loss=0.707\n",
            "epoch: 45, discriminator_real_loss=0.022, discriminator_fake_loss=0.062, generator_loss=0.738\n",
            "epoch: 46, discriminator_real_loss=0.048, discriminator_fake_loss=0.005, generator_loss=0.696\n",
            "epoch: 47, discriminator_real_loss=0.016, discriminator_fake_loss=0.040, generator_loss=0.692\n",
            "epoch: 48, discriminator_real_loss=0.082, discriminator_fake_loss=0.016, generator_loss=0.620\n",
            "epoch: 49, discriminator_real_loss=0.070, discriminator_fake_loss=0.017, generator_loss=0.661\n",
            "epoch: 50, discriminator_real_loss=0.158, discriminator_fake_loss=0.008, generator_loss=0.640\n",
            "epoch: 51, discriminator_real_loss=0.010, discriminator_fake_loss=0.021, generator_loss=0.687\n",
            "epoch: 52, discriminator_real_loss=0.051, discriminator_fake_loss=0.047, generator_loss=0.724\n",
            "epoch: 53, discriminator_real_loss=0.056, discriminator_fake_loss=0.110, generator_loss=0.749\n",
            "epoch: 54, discriminator_real_loss=0.039, discriminator_fake_loss=0.011, generator_loss=0.671\n",
            "epoch: 55, discriminator_real_loss=0.034, discriminator_fake_loss=0.030, generator_loss=0.699\n",
            "epoch: 56, discriminator_real_loss=0.027, discriminator_fake_loss=0.040, generator_loss=0.714\n",
            "epoch: 57, discriminator_real_loss=0.034, discriminator_fake_loss=0.052, generator_loss=0.704\n",
            "epoch: 58, discriminator_real_loss=0.077, discriminator_fake_loss=0.014, generator_loss=0.634\n",
            "epoch: 59, discriminator_real_loss=0.026, discriminator_fake_loss=0.040, generator_loss=0.683\n",
            "epoch: 60, discriminator_real_loss=0.029, discriminator_fake_loss=0.065, generator_loss=0.733\n",
            "epoch: 61, discriminator_real_loss=0.014, discriminator_fake_loss=0.020, generator_loss=0.696\n",
            "epoch: 62, discriminator_real_loss=0.038, discriminator_fake_loss=0.044, generator_loss=0.699\n",
            "epoch: 63, discriminator_real_loss=0.046, discriminator_fake_loss=0.007, generator_loss=0.639\n",
            "epoch: 64, discriminator_real_loss=0.030, discriminator_fake_loss=0.012, generator_loss=0.656\n",
            "epoch: 65, discriminator_real_loss=0.044, discriminator_fake_loss=0.015, generator_loss=0.668\n",
            "epoch: 66, discriminator_real_loss=0.022, discriminator_fake_loss=0.028, generator_loss=0.733\n",
            "epoch: 67, discriminator_real_loss=0.019, discriminator_fake_loss=0.021, generator_loss=0.662\n",
            "epoch: 68, discriminator_real_loss=0.011, discriminator_fake_loss=0.010, generator_loss=0.676\n",
            "epoch: 69, discriminator_real_loss=0.030, discriminator_fake_loss=0.028, generator_loss=0.711\n",
            "epoch: 70, discriminator_real_loss=0.013, discriminator_fake_loss=0.027, generator_loss=0.653\n",
            "epoch: 71, discriminator_real_loss=0.012, discriminator_fake_loss=0.010, generator_loss=0.677\n",
            "epoch: 72, discriminator_real_loss=0.041, discriminator_fake_loss=0.011, generator_loss=0.735\n",
            "epoch: 73, discriminator_real_loss=0.013, discriminator_fake_loss=0.029, generator_loss=0.732\n",
            "epoch: 74, discriminator_real_loss=0.012, discriminator_fake_loss=0.036, generator_loss=0.695\n",
            "epoch: 75, discriminator_real_loss=0.020, discriminator_fake_loss=0.050, generator_loss=0.764\n",
            "epoch: 76, discriminator_real_loss=0.038, discriminator_fake_loss=0.047, generator_loss=0.724\n",
            "epoch: 77, discriminator_real_loss=0.040, discriminator_fake_loss=0.011, generator_loss=0.629\n",
            "epoch: 78, discriminator_real_loss=0.024, discriminator_fake_loss=0.045, generator_loss=0.763\n",
            "epoch: 79, discriminator_real_loss=0.026, discriminator_fake_loss=0.012, generator_loss=0.680\n",
            "epoch: 80, discriminator_real_loss=0.009, discriminator_fake_loss=0.024, generator_loss=0.728\n",
            "epoch: 81, discriminator_real_loss=0.033, discriminator_fake_loss=0.008, generator_loss=0.640\n",
            "epoch: 82, discriminator_real_loss=0.014, discriminator_fake_loss=0.050, generator_loss=0.729\n",
            "epoch: 83, discriminator_real_loss=0.031, discriminator_fake_loss=0.008, generator_loss=0.633\n",
            "epoch: 84, discriminator_real_loss=0.031, discriminator_fake_loss=0.023, generator_loss=0.703\n",
            "epoch: 85, discriminator_real_loss=0.037, discriminator_fake_loss=0.037, generator_loss=0.699\n",
            "epoch: 86, discriminator_real_loss=0.031, discriminator_fake_loss=0.014, generator_loss=0.693\n",
            "epoch: 87, discriminator_real_loss=0.024, discriminator_fake_loss=0.045, generator_loss=0.748\n",
            "epoch: 88, discriminator_real_loss=0.025, discriminator_fake_loss=0.022, generator_loss=0.668\n",
            "epoch: 89, discriminator_real_loss=0.026, discriminator_fake_loss=0.014, generator_loss=0.678\n",
            "epoch: 90, discriminator_real_loss=0.013, discriminator_fake_loss=0.026, generator_loss=0.721\n",
            "epoch: 91, discriminator_real_loss=0.022, discriminator_fake_loss=0.006, generator_loss=0.750\n",
            "epoch: 92, discriminator_real_loss=0.019, discriminator_fake_loss=0.022, generator_loss=0.728\n",
            "epoch: 93, discriminator_real_loss=0.013, discriminator_fake_loss=0.007, generator_loss=0.728\n",
            "epoch: 94, discriminator_real_loss=0.018, discriminator_fake_loss=0.024, generator_loss=0.739\n",
            "epoch: 95, discriminator_real_loss=0.036, discriminator_fake_loss=0.018, generator_loss=0.645\n",
            "epoch: 96, discriminator_real_loss=0.011, discriminator_fake_loss=0.014, generator_loss=0.731\n",
            "epoch: 97, discriminator_real_loss=0.024, discriminator_fake_loss=0.015, generator_loss=0.701\n",
            "epoch: 98, discriminator_real_loss=0.021, discriminator_fake_loss=0.017, generator_loss=0.683\n",
            "epoch: 99, discriminator_real_loss=0.007, discriminator_fake_loss=0.020, generator_loss=0.744\n",
            "epoch: 100, discriminator_real_loss=0.032, discriminator_fake_loss=0.019, generator_loss=0.660\n",
            "epoch: 101, discriminator_real_loss=0.048, discriminator_fake_loss=0.007, generator_loss=0.764\n",
            "epoch: 102, discriminator_real_loss=0.054, discriminator_fake_loss=0.036, generator_loss=0.735\n",
            "epoch: 103, discriminator_real_loss=0.038, discriminator_fake_loss=0.012, generator_loss=0.647\n",
            "epoch: 104, discriminator_real_loss=0.008, discriminator_fake_loss=0.012, generator_loss=0.704\n",
            "epoch: 105, discriminator_real_loss=0.006, discriminator_fake_loss=0.016, generator_loss=0.738\n",
            "epoch: 106, discriminator_real_loss=0.013, discriminator_fake_loss=0.023, generator_loss=0.702\n",
            "epoch: 107, discriminator_real_loss=0.008, discriminator_fake_loss=0.044, generator_loss=0.763\n",
            "epoch: 108, discriminator_real_loss=0.010, discriminator_fake_loss=0.011, generator_loss=0.687\n",
            "epoch: 109, discriminator_real_loss=0.010, discriminator_fake_loss=0.034, generator_loss=0.754\n",
            "epoch: 110, discriminator_real_loss=0.028, discriminator_fake_loss=0.007, generator_loss=0.716\n",
            "epoch: 111, discriminator_real_loss=0.015, discriminator_fake_loss=0.014, generator_loss=0.712\n",
            "epoch: 112, discriminator_real_loss=0.007, discriminator_fake_loss=0.015, generator_loss=0.730\n",
            "epoch: 113, discriminator_real_loss=0.028, discriminator_fake_loss=0.006, generator_loss=0.647\n",
            "epoch: 114, discriminator_real_loss=0.011, discriminator_fake_loss=0.020, generator_loss=0.743\n",
            "epoch: 115, discriminator_real_loss=0.020, discriminator_fake_loss=0.064, generator_loss=0.803\n",
            "epoch: 116, discriminator_real_loss=0.016, discriminator_fake_loss=0.027, generator_loss=0.747\n",
            "epoch: 117, discriminator_real_loss=0.021, discriminator_fake_loss=0.033, generator_loss=0.712\n",
            "epoch: 118, discriminator_real_loss=0.015, discriminator_fake_loss=0.024, generator_loss=0.708\n",
            "epoch: 119, discriminator_real_loss=0.005, discriminator_fake_loss=0.007, generator_loss=0.710\n",
            "epoch: 120, discriminator_real_loss=0.167, discriminator_fake_loss=0.034, generator_loss=0.612\n",
            "epoch: 121, discriminator_real_loss=0.013, discriminator_fake_loss=0.023, generator_loss=0.723\n",
            "epoch: 122, discriminator_real_loss=0.025, discriminator_fake_loss=0.026, generator_loss=0.642\n",
            "epoch: 123, discriminator_real_loss=0.010, discriminator_fake_loss=0.007, generator_loss=0.708\n",
            "epoch: 124, discriminator_real_loss=0.013, discriminator_fake_loss=0.006, generator_loss=0.712\n",
            "epoch: 125, discriminator_real_loss=0.022, discriminator_fake_loss=0.025, generator_loss=0.756\n",
            "epoch: 126, discriminator_real_loss=0.010, discriminator_fake_loss=0.006, generator_loss=0.699\n",
            "epoch: 127, discriminator_real_loss=0.011, discriminator_fake_loss=0.004, generator_loss=0.727\n",
            "epoch: 128, discriminator_real_loss=0.030, discriminator_fake_loss=0.005, generator_loss=0.738\n",
            "epoch: 129, discriminator_real_loss=0.024, discriminator_fake_loss=0.012, generator_loss=0.710\n",
            "epoch: 130, discriminator_real_loss=0.008, discriminator_fake_loss=0.006, generator_loss=0.704\n",
            "epoch: 131, discriminator_real_loss=0.017, discriminator_fake_loss=0.015, generator_loss=0.716\n",
            "epoch: 132, discriminator_real_loss=0.008, discriminator_fake_loss=0.010, generator_loss=0.722\n",
            "epoch: 133, discriminator_real_loss=0.013, discriminator_fake_loss=0.007, generator_loss=0.760\n",
            "epoch: 134, discriminator_real_loss=0.009, discriminator_fake_loss=0.013, generator_loss=0.729\n",
            "epoch: 135, discriminator_real_loss=0.023, discriminator_fake_loss=0.015, generator_loss=0.694\n",
            "epoch: 136, discriminator_real_loss=0.009, discriminator_fake_loss=0.007, generator_loss=0.747\n",
            "epoch: 137, discriminator_real_loss=0.066, discriminator_fake_loss=0.036, generator_loss=0.685\n",
            "epoch: 138, discriminator_real_loss=0.009, discriminator_fake_loss=0.021, generator_loss=0.736\n",
            "epoch: 139, discriminator_real_loss=0.066, discriminator_fake_loss=0.026, generator_loss=0.690\n",
            "epoch: 140, discriminator_real_loss=0.011, discriminator_fake_loss=0.013, generator_loss=0.702\n",
            "epoch: 141, discriminator_real_loss=0.013, discriminator_fake_loss=0.014, generator_loss=0.723\n",
            "epoch: 142, discriminator_real_loss=0.008, discriminator_fake_loss=0.008, generator_loss=0.789\n",
            "epoch: 143, discriminator_real_loss=0.017, discriminator_fake_loss=0.018, generator_loss=0.725\n",
            "epoch: 144, discriminator_real_loss=0.019, discriminator_fake_loss=0.044, generator_loss=0.766\n",
            "epoch: 145, discriminator_real_loss=0.012, discriminator_fake_loss=0.008, generator_loss=0.712\n",
            "epoch: 146, discriminator_real_loss=0.021, discriminator_fake_loss=0.023, generator_loss=0.756\n",
            "epoch: 147, discriminator_real_loss=0.012, discriminator_fake_loss=0.013, generator_loss=0.705\n",
            "epoch: 148, discriminator_real_loss=0.015, discriminator_fake_loss=0.008, generator_loss=0.757\n",
            "epoch: 149, discriminator_real_loss=0.008, discriminator_fake_loss=0.009, generator_loss=0.746\n",
            "epoch: 150, discriminator_real_loss=0.007, discriminator_fake_loss=0.007, generator_loss=0.699\n",
            "epoch: 151, discriminator_real_loss=0.019, discriminator_fake_loss=0.007, generator_loss=0.754\n",
            "epoch: 152, discriminator_real_loss=0.007, discriminator_fake_loss=0.021, generator_loss=0.740\n",
            "epoch: 153, discriminator_real_loss=0.008, discriminator_fake_loss=0.007, generator_loss=0.757\n",
            "epoch: 154, discriminator_real_loss=0.013, discriminator_fake_loss=0.014, generator_loss=0.694\n",
            "epoch: 155, discriminator_real_loss=0.026, discriminator_fake_loss=0.017, generator_loss=0.735\n",
            "epoch: 156, discriminator_real_loss=0.009, discriminator_fake_loss=0.054, generator_loss=0.781\n",
            "epoch: 157, discriminator_real_loss=0.006, discriminator_fake_loss=0.006, generator_loss=0.724\n",
            "epoch: 158, discriminator_real_loss=0.007, discriminator_fake_loss=0.012, generator_loss=0.724\n",
            "epoch: 159, discriminator_real_loss=0.008, discriminator_fake_loss=0.008, generator_loss=0.725\n",
            "epoch: 160, discriminator_real_loss=0.008, discriminator_fake_loss=0.006, generator_loss=0.717\n",
            "epoch: 161, discriminator_real_loss=0.008, discriminator_fake_loss=0.034, generator_loss=0.779\n",
            "epoch: 162, discriminator_real_loss=0.006, discriminator_fake_loss=0.007, generator_loss=0.716\n",
            "epoch: 163, discriminator_real_loss=0.015, discriminator_fake_loss=0.014, generator_loss=0.711\n",
            "epoch: 164, discriminator_real_loss=0.008, discriminator_fake_loss=0.005, generator_loss=0.690\n",
            "epoch: 165, discriminator_real_loss=0.006, discriminator_fake_loss=0.010, generator_loss=0.757\n",
            "epoch: 166, discriminator_real_loss=0.005, discriminator_fake_loss=0.007, generator_loss=0.709\n",
            "epoch: 167, discriminator_real_loss=0.059, discriminator_fake_loss=0.017, generator_loss=0.744\n",
            "epoch: 168, discriminator_real_loss=0.011, discriminator_fake_loss=0.013, generator_loss=0.708\n",
            "epoch: 169, discriminator_real_loss=0.023, discriminator_fake_loss=0.011, generator_loss=0.738\n",
            "epoch: 170, discriminator_real_loss=0.006, discriminator_fake_loss=0.023, generator_loss=0.750\n",
            "epoch: 171, discriminator_real_loss=0.008, discriminator_fake_loss=0.010, generator_loss=0.708\n",
            "epoch: 172, discriminator_real_loss=0.006, discriminator_fake_loss=0.005, generator_loss=0.697\n",
            "epoch: 173, discriminator_real_loss=0.016, discriminator_fake_loss=0.014, generator_loss=0.743\n",
            "epoch: 174, discriminator_real_loss=0.013, discriminator_fake_loss=0.014, generator_loss=0.720\n",
            "epoch: 175, discriminator_real_loss=0.007, discriminator_fake_loss=0.011, generator_loss=0.731\n",
            "epoch: 176, discriminator_real_loss=0.009, discriminator_fake_loss=0.013, generator_loss=0.732\n",
            "epoch: 177, discriminator_real_loss=0.014, discriminator_fake_loss=0.010, generator_loss=0.693\n",
            "epoch: 178, discriminator_real_loss=0.008, discriminator_fake_loss=0.005, generator_loss=0.711\n",
            "epoch: 179, discriminator_real_loss=0.011, discriminator_fake_loss=0.010, generator_loss=0.723\n",
            "epoch: 180, discriminator_real_loss=0.008, discriminator_fake_loss=0.007, generator_loss=0.773\n",
            "epoch: 181, discriminator_real_loss=0.007, discriminator_fake_loss=0.012, generator_loss=0.747\n",
            "epoch: 182, discriminator_real_loss=0.016, discriminator_fake_loss=0.010, generator_loss=0.714\n",
            "epoch: 183, discriminator_real_loss=0.007, discriminator_fake_loss=0.013, generator_loss=0.751\n",
            "epoch: 184, discriminator_real_loss=0.008, discriminator_fake_loss=0.024, generator_loss=0.734\n",
            "epoch: 185, discriminator_real_loss=0.029, discriminator_fake_loss=0.012, generator_loss=0.696\n",
            "epoch: 186, discriminator_real_loss=0.031, discriminator_fake_loss=0.006, generator_loss=0.691\n",
            "epoch: 187, discriminator_real_loss=0.024, discriminator_fake_loss=0.008, generator_loss=0.712\n",
            "epoch: 188, discriminator_real_loss=0.009, discriminator_fake_loss=0.013, generator_loss=0.767\n",
            "epoch: 189, discriminator_real_loss=0.007, discriminator_fake_loss=0.009, generator_loss=0.732\n",
            "epoch: 190, discriminator_real_loss=0.008, discriminator_fake_loss=0.016, generator_loss=0.730\n",
            "epoch: 191, discriminator_real_loss=0.014, discriminator_fake_loss=0.009, generator_loss=0.711\n",
            "epoch: 192, discriminator_real_loss=0.005, discriminator_fake_loss=0.007, generator_loss=0.743\n",
            "epoch: 193, discriminator_real_loss=0.008, discriminator_fake_loss=0.010, generator_loss=0.745\n",
            "epoch: 194, discriminator_real_loss=0.006, discriminator_fake_loss=0.011, generator_loss=0.769\n",
            "epoch: 195, discriminator_real_loss=0.009, discriminator_fake_loss=0.006, generator_loss=0.716\n",
            "epoch: 196, discriminator_real_loss=0.008, discriminator_fake_loss=0.025, generator_loss=0.786\n",
            "epoch: 197, discriminator_real_loss=0.008, discriminator_fake_loss=0.006, generator_loss=0.708\n",
            "epoch: 198, discriminator_real_loss=0.013, discriminator_fake_loss=0.007, generator_loss=0.756\n",
            "epoch: 199, discriminator_real_loss=0.012, discriminator_fake_loss=0.009, generator_loss=0.721\n",
            "epoch: 200, discriminator_real_loss=0.049, discriminator_fake_loss=0.038, generator_loss=0.764\n",
            "epoch: 201, discriminator_real_loss=0.012, discriminator_fake_loss=0.007, generator_loss=0.717\n",
            "epoch: 202, discriminator_real_loss=0.009, discriminator_fake_loss=0.008, generator_loss=0.777\n",
            "epoch: 203, discriminator_real_loss=0.009, discriminator_fake_loss=0.061, generator_loss=0.765\n",
            "epoch: 204, discriminator_real_loss=0.020, discriminator_fake_loss=0.009, generator_loss=0.719\n",
            "epoch: 205, discriminator_real_loss=0.013, discriminator_fake_loss=0.046, generator_loss=0.752\n",
            "epoch: 206, discriminator_real_loss=0.021, discriminator_fake_loss=0.036, generator_loss=0.741\n",
            "epoch: 207, discriminator_real_loss=0.007, discriminator_fake_loss=0.015, generator_loss=0.748\n",
            "epoch: 208, discriminator_real_loss=0.017, discriminator_fake_loss=0.027, generator_loss=0.720\n",
            "epoch: 209, discriminator_real_loss=0.007, discriminator_fake_loss=0.022, generator_loss=0.746\n",
            "epoch: 210, discriminator_real_loss=0.009, discriminator_fake_loss=0.014, generator_loss=0.758\n",
            "epoch: 211, discriminator_real_loss=0.006, discriminator_fake_loss=0.010, generator_loss=0.729\n",
            "epoch: 212, discriminator_real_loss=0.019, discriminator_fake_loss=0.016, generator_loss=0.725\n",
            "epoch: 213, discriminator_real_loss=0.041, discriminator_fake_loss=0.018, generator_loss=0.705\n",
            "epoch: 214, discriminator_real_loss=0.013, discriminator_fake_loss=0.010, generator_loss=0.690\n",
            "epoch: 215, discriminator_real_loss=0.007, discriminator_fake_loss=0.010, generator_loss=0.708\n",
            "epoch: 216, discriminator_real_loss=0.008, discriminator_fake_loss=0.021, generator_loss=0.728\n",
            "epoch: 217, discriminator_real_loss=0.084, discriminator_fake_loss=0.010, generator_loss=0.809\n",
            "epoch: 218, discriminator_real_loss=0.012, discriminator_fake_loss=0.013, generator_loss=0.709\n",
            "epoch: 219, discriminator_real_loss=0.006, discriminator_fake_loss=0.012, generator_loss=0.751\n",
            "epoch: 220, discriminator_real_loss=0.013, discriminator_fake_loss=0.008, generator_loss=0.743\n",
            "epoch: 221, discriminator_real_loss=0.017, discriminator_fake_loss=0.009, generator_loss=0.671\n",
            "epoch: 222, discriminator_real_loss=0.024, discriminator_fake_loss=0.013, generator_loss=0.714\n",
            "epoch: 223, discriminator_real_loss=0.004, discriminator_fake_loss=0.006, generator_loss=0.684\n",
            "epoch: 224, discriminator_real_loss=0.007, discriminator_fake_loss=0.009, generator_loss=0.746\n",
            "epoch: 225, discriminator_real_loss=0.012, discriminator_fake_loss=0.007, generator_loss=0.741\n",
            "epoch: 226, discriminator_real_loss=0.014, discriminator_fake_loss=0.017, generator_loss=0.741\n",
            "epoch: 227, discriminator_real_loss=0.008, discriminator_fake_loss=0.007, generator_loss=0.666\n",
            "epoch: 228, discriminator_real_loss=0.009, discriminator_fake_loss=0.007, generator_loss=0.722\n",
            "epoch: 229, discriminator_real_loss=0.009, discriminator_fake_loss=0.006, generator_loss=0.736\n",
            "epoch: 230, discriminator_real_loss=0.007, discriminator_fake_loss=0.008, generator_loss=0.728\n",
            "epoch: 231, discriminator_real_loss=0.008, discriminator_fake_loss=0.009, generator_loss=0.747\n",
            "epoch: 232, discriminator_real_loss=0.007, discriminator_fake_loss=0.021, generator_loss=0.767\n",
            "epoch: 233, discriminator_real_loss=0.009, discriminator_fake_loss=0.006, generator_loss=0.724\n",
            "epoch: 234, discriminator_real_loss=0.016, discriminator_fake_loss=0.041, generator_loss=0.774\n",
            "epoch: 235, discriminator_real_loss=0.005, discriminator_fake_loss=0.014, generator_loss=0.734\n",
            "epoch: 236, discriminator_real_loss=0.013, discriminator_fake_loss=0.015, generator_loss=0.723\n",
            "epoch: 237, discriminator_real_loss=0.010, discriminator_fake_loss=0.008, generator_loss=0.758\n",
            "epoch: 238, discriminator_real_loss=0.010, discriminator_fake_loss=0.006, generator_loss=0.689\n",
            "epoch: 239, discriminator_real_loss=0.053, discriminator_fake_loss=0.088, generator_loss=0.789\n",
            "epoch: 240, discriminator_real_loss=0.032, discriminator_fake_loss=0.006, generator_loss=0.631\n",
            "epoch: 241, discriminator_real_loss=0.024, discriminator_fake_loss=0.005, generator_loss=0.597\n",
            "epoch: 242, discriminator_real_loss=0.022, discriminator_fake_loss=0.006, generator_loss=0.717\n",
            "epoch: 243, discriminator_real_loss=0.007, discriminator_fake_loss=0.054, generator_loss=0.783\n",
            "epoch: 244, discriminator_real_loss=0.081, discriminator_fake_loss=0.009, generator_loss=0.736\n",
            "epoch: 245, discriminator_real_loss=0.006, discriminator_fake_loss=0.008, generator_loss=0.749\n",
            "epoch: 246, discriminator_real_loss=0.008, discriminator_fake_loss=0.028, generator_loss=0.740\n",
            "epoch: 247, discriminator_real_loss=0.008, discriminator_fake_loss=0.008, generator_loss=0.734\n",
            "epoch: 248, discriminator_real_loss=0.011, discriminator_fake_loss=0.005, generator_loss=0.666\n",
            "epoch: 249, discriminator_real_loss=0.007, discriminator_fake_loss=0.016, generator_loss=0.750\n",
            "epoch: 250, discriminator_real_loss=0.006, discriminator_fake_loss=0.006, generator_loss=0.739\n",
            "epoch: 251, discriminator_real_loss=0.014, discriminator_fake_loss=0.009, generator_loss=0.645\n",
            "epoch: 252, discriminator_real_loss=0.010, discriminator_fake_loss=0.006, generator_loss=0.748\n",
            "epoch: 253, discriminator_real_loss=0.005, discriminator_fake_loss=0.005, generator_loss=0.697\n",
            "epoch: 254, discriminator_real_loss=0.012, discriminator_fake_loss=0.029, generator_loss=0.756\n",
            "epoch: 255, discriminator_real_loss=0.008, discriminator_fake_loss=0.006, generator_loss=0.705\n",
            "epoch: 256, discriminator_real_loss=0.024, discriminator_fake_loss=0.006, generator_loss=0.623\n",
            "epoch: 257, discriminator_real_loss=0.015, discriminator_fake_loss=0.006, generator_loss=0.751\n",
            "epoch: 258, discriminator_real_loss=0.009, discriminator_fake_loss=0.008, generator_loss=0.724\n",
            "epoch: 259, discriminator_real_loss=0.014, discriminator_fake_loss=0.009, generator_loss=0.748\n",
            "epoch: 260, discriminator_real_loss=0.019, discriminator_fake_loss=0.019, generator_loss=0.721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gij7UAYvoFIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}